# Sign Language Detection using Mediapipe and Custom LSTM Model

This project aims to detect and recognize sign language gestures in real-time using a custom-trained LSTM model and the Mediapipe library for extracting keypoints. The model predicts three sign language gestures from a live webcam feed.

## Table of Contents
- [Installation](#installation)
- [Usage](#usage)
- [Model Architecture](#model-architecture)
- [Dataset](#dataset)
- [Live Detection](#live-detection)
- [Contributing](#contributing)
- [License](#license)

## Installation

To set up the environment for this project, follow these steps:

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/sign-language-detection.git
   cd sign-language-detection

2. Install the required dependencies listed in [requirements.txt](requirements.txt):
   ```bash
   pip install -r requirements.txt
